from fastapi import FastAPI, HTTPException, Query, Depends
from fastapi.middleware.cors import CORSMiddleware

from pydantic import BaseModel, constr
import requests
import json
from typing import Annotated
import datetime

from db_control import crud, mymodels_MySQL

from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS 
from langchain.chains import RetrievalQA
from langchain_community.llms import OpenAI
from pinecone import Pinecone, ServerlessSpec

from typing import List, Optional
import openai

import numpy as np
import os

# FastAPI ã‚¢ãƒ—ãƒªã®åˆæœŸåŒ–
app = FastAPI()

# OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ä½œæˆ
client = OpenAI()

# CORSãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã®è¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    # allow_origins=["https://tech0-gen-9-step3-1-node-13.azurewebsites.net"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# MySQLã®ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã—ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–æ™‚ã«ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ
from db_control.create_tables_MySQL import init_db
init_db()

# ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
openai.api_key = os.getenv("OPENAI_API_KEY")
pinecone_api_key = os.getenv("PINECONE_API_KEY")
pinecone_environment = os.getenv("PINECONE_ENVIRONMENT")

# Pinecone ã®åˆæœŸåŒ–
pc = Pinecone(api_key=pinecone_api_key, environment=pinecone_environment)
index_name = "knowledge-index"

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ç¢ºèªã¾ãŸã¯ä½œæˆ
if index_name not in pc.list_indexes().names():
    pc.create_index(
        name=index_name,
        dimension=1536,  # ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®æ¬¡å…ƒæ•°
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-east-1")
    )
index = pc.Index(index_name)

# ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ– (OpenAI Embeddings ã‚’ä½¿ç”¨)
model = OpenAIEmbeddings(model="text-embedding-ada-002")


class Meeting(BaseModel):
    id: int
    user_id: int
    title: str
    summary: str
    knowledge: str
    issues: str
    solutionKnowledge: str
    created_at: datetime.datetime | None = None


@app.get("/")
def read_root():
    return {"message": "Welcome to the FastAPI server!"}


@app.post("/meeting")
def post_finalized_meeting(newMeeting: Meeting):
    if newMeeting.created_at is None:
        newMeeting.created_at = datetime.datetime.now()
        
    # ğŸ”¥ 1. Knowledge ã¨ Issues ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã€€â†’ã€€ğŸ”¥Knowledgeã ã‘ã§ã„ã„ã®ã§ã¯ï¼Ÿ
    try:
        knowledge_vector = model.embed_query(newMeeting.knowledge)
        issues_vector = model.embed_query(newMeeting.issues)
        print("âœ… ãƒ™ã‚¯ãƒˆãƒ«åŒ–å®Œäº† - Knowledge Vector:", knowledge_vector[:5], "Issues Vector:", issues_vector[:5])
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")


    # ğŸ”¥ 2. Pinecone ã«ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¿å­˜ã€€â†’ã€€ğŸ”¥Knowledgeã ã‘ã§ã„ã„ã®ã§ã¯ï¼Ÿã¾ãŸã€knowledge-ãŒä¸è¦ã§ã€ãƒŠãƒ¬ãƒƒã‚¸ã®IDã¨textã®é …ç›®ãŒã‚ã‚Œã°
    try:
        index.upsert([
            (f"knowledge-{newMeeting.id}", knowledge_vector, {"text": newMeeting.knowledge, "type": "knowledge"}),
            (f"issues-{newMeeting.id}", issues_vector, {"text": newMeeting.issues, "type": "issues"})
        ])
        print(f"âœ… Pinecone ã«ä¿å­˜æˆåŠŸ - ID: {newMeeting.id}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Pinecone ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")


    # ğŸ”¥ 3. Pinecone ã§ç´¢é¡ä¼¼æ¤œã‚’å®Ÿè¡Œ (Issues ã«å¯¾ã™ã‚‹ Knowledge ã®æ¤œç´¢)
    try:
        response = index.query(
            vector=issues_vector,
            top_k=5,
            include_metadata=True
        )
        print(f"âœ… é¡ä¼¼æ¤œç´¢å®Œäº† - ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ•°: {len(response['matches'])}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Pinecone æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
    

    # ğŸ”¥ 4. æ¤œç´¢çµæœã‚’è¦ç´„ã™ã‚‹
    try:
        knowledge_texts = [match['metadata']['text'] for match in response['matches']]
        combined_knowledge = "\n".join(knowledge_texts)
        print(f"âœ… çŸ¥è­˜ã®çµåˆå®Œäº† - {combined_knowledge[:100]}")  # æœ€åˆã®100æ–‡å­—ã‚’è¡¨ç¤º

        summary_response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,
            max_tokens=500
        )
        summarized_text = summary_response.choices[0].message["content"]
        print(f"âœ… è¦ç´„æˆåŠŸ - {summarized_text[:100]}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"OpenAI API ã‚¨ãƒ©ãƒ¼: {str(e)}")


    # ğŸ”¥ 5. MySQL ã«ä¿å­˜
    try:
        db = SessionLocal()
        insert_query = text("""
            INSERT INTO meetings (id, user_id, title, summary, solutionKnowledge, created_at)
            VALUES (:id, :user_id, :title, :summary, :solutionKnowledge, :created_at)
        """)
        db.execute(insert_query, {
            "id": newMeeting.id,
            "user_id": newMeeting.user_id,
            "title": newMeeting.title,
            "summary": newMeeting.summary,
            "solutionKnowledge": summarized_text,
            "created_at": newMeeting.created_at
        })
        db.commit()
        print("âœ… MySQL ã¸ã®ä¿å­˜å®Œäº†")
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"MySQL ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
    finally:
        db.close()


    print(f"å—ã‘å–ã£ãŸãƒ‡ãƒ¼ã‚¿ï¼š {newMeeting}")
    
    stats = index.describe_index_stats()
    print(stats)
    
    return {"res": "ok", "ID": newMeeting.id}


# @app.post("/add_knowledge/")
# def add_knowledge(content: str, db = Depends(get_db)):
    # ãƒŠãƒ¬ãƒƒã‚¸ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
#    vector = model.encode(content).astype(np.float32)
#    index.add(np.array([vector]))  # FAISS ã«è¿½åŠ 

    # ãƒ™ã‚¯ãƒˆãƒ«ã‚’ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã—ã¦ä¿å­˜
#    vector_data = vector.tobytes()
#    db.execute(
#        text("INSERT INTO knowledge (content, vector) VALUES (:content, :vector)"),
#        {"content": content, "vector": vector_data}
#    )
#    db.commit()
#    return {"status": "Knowledge added successfully"}

#@app.post("/search_knowledge/")
#def search_knowledge(query: str):
#    query_vector = model.encode(query).astype(np.float32)
#    D, I = index.search(np.array([query_vector]), k=5)  # ä¸Šä½5ä»¶ã‚’æ¤œç´¢

#    results = []
#    for idx in I[0]:
#        if idx == -1:
#            continue
#        results.append({"index": int(idx), "score": float(D[0][0])})
    
#    return {"results": results}

#@app.post("/generate_response/")
#def generate_response(query: str):
#    response = openai.ChatCompletion.create(
#        model="gpt-4",
#        messages=[
#            {"role": "system", "content": "You are a helpful assistant."},
#            {"role": "user", "content": query},
#        ]
#    )
#    return {"response": response.choices[0].message["content"]}






# ä¿®æ­£å¾Œã®ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®å†…å®¹ã‚’DBã«ç™»éŒ²ï¼ˆãƒŠãƒ¬ãƒƒã‚¸ã¨ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã¯ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰


# DBã«ç™»éŒ²ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸãƒãƒ£ãƒ¬ãƒ³ã‚¸ã«å¯¾ã—ã¦éå»ã®ãƒŠãƒ¬ãƒƒã‚¸ã‚’æ¤œç´¢

# ãƒŠãƒ¬ãƒƒã‚¸ã‚’ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹å¿œç­”æ–‡ã¨å‚ç…§å…ƒã¨ãªã‚‹ãƒŠãƒ¬ãƒƒã‚¸ã‚’å–å¾—

# ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®å¿œç­”æ–‡ã¨å‚ç…§å…ƒã¨ãªã‚‹ãƒŠãƒ¬ãƒƒã‚¸ã‚’DBã«ä¿å­˜




